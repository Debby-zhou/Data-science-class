{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.444300\n",
      "n_neighbors: 3, average score: 0.713366\n",
      "n_neighbors: 5, average score: 0.640089\n",
      "n_neighbors: 10, average score: 0.674070\n",
      "n_neighbors: 20, average score: 0.620623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xea6cbf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_errors, validation_errors = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_errors.mean(axis=1), label=\"training error\")\n",
    "plt.plot(n_neighbors, validation_errors.mean(axis=1), label=\"validation error\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot is the mirror image of the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.049787\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.106841\n",
      "C: 0.001000, gamma: 0.100000, average score: 0.004215\n",
      "C: 0.001000, gamma: 1.000000, average score: 0.004421\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.006461\n",
      "C: 0.010000, gamma: 0.010000, average score: 0.002100\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.058769\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.017296\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.118302\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.113527\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.518388\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.498491\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.159936\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.592062\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.643504\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.690715\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.573857\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.624327\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.657352\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.739302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.06668382267595185, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.005612395667913939, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.04027064464146379, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.06388407900465132, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=-0.003773629265007461, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.03808970218500196, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=-0.051517657629481795, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=0.0043626505127125625, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.02818789055750281, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.05304824790338314, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] .... C=0.001, gamma=1, score=0.0032307363146556467, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] .... C=0.001, gamma=1, score=-0.029304011374702513, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=-0.06360226577351158, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=-0.0035887905989193673, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=-0.03787771406308971, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .. C=0.01, gamma=0.01, score=-0.036117888704428225, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.014590484944840165, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=-0.01626150855501196, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=0.057330379839469765, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.09024200107131297, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.08381630237867121, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.05033074735439813, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.07697840687484392, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ........ C=0.01, gamma=1, score=0.0675669311032091, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .... C=0.1, gamma=0.001, score=-0.0334016090969782, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.016394748770377054, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .. C=0.1, gamma=0.001, score=-0.014178455390326581, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.1686006955792223, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.17352382546906975, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.15934368494301498, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.48522764946490426, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5103615079130233, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5221248461632879, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4782404984823826, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4880553932202515, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5027310032438936, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.18424428893822375, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.18247089841765385, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.17293500930841255, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5470534171427488, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5981120274581513, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5894761831233195, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.5426786105486953, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .......... C=1, gamma=0.1, score=0.751842799338719, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6679759355773889, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6262285808216853, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.792109506600085, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7057555454247684, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5405105628493178, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6187821440259724, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5870331610773459, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ........ C=10, gamma=0.01, score=0.536409076618731, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6977683314327758, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=10, gamma=0.01, score=0.6187785469058462, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.5142382243316695, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7581329669302758, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6779754028502514, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.6794626590296065, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8456410181633699, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7423619991445223, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7550582997816707\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] .. C=0.001, gamma=0.001, score=-0.5124313346921585, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ... C=0.001, gamma=0.01, score=-0.5107952539607039, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .... C=0.001, gamma=0.1, score=-0.5038786764642951, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ...... C=0.001, gamma=1, score=-0.5047400086433778, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ... C=0.01, gamma=0.001, score=-0.5106212926673603, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=-0.5018653161688389, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=-0.48437636445392585, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=-0.44468115300641325, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .... C=0.1, gamma=0.001, score=-0.5027288888416843, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=-0.4049157624580251, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.13163756011309047, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ........ C=0.1, gamma=1, score=0.11361162201521426, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ..... C=1, gamma=0.001, score=-0.38292804686121573, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ....... C=1, gamma=0.01, score=0.24849606455199025, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ........ C=1, gamma=0.1, score=0.45912464731779357, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.5573626081225789, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ..... C=10, gamma=0.001, score=0.24245473775962215, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ...... C=10, gamma=0.01, score=0.32360623291972823, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.4710883241077158, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7081104333026091, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
